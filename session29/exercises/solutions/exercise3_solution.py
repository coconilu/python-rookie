#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Session29 ç»ƒä¹ 3è§£å†³æ–¹æ¡ˆ: æ€§èƒ½æµ‹è¯•å’Œè°ƒè¯•æŠ€æœ¯

è¿™æ˜¯exercise3.pyçš„å®Œæ•´è§£å†³æ–¹æ¡ˆï¼Œå±•ç¤ºäº†å¦‚ä½•è¿›è¡Œæ€§èƒ½æµ‹è¯•å’Œè°ƒè¯•ã€‚

ä½œè€…: Pythonæ•™ç¨‹å›¢é˜Ÿ
"""

import time
import cProfile
import pstats
import tracemalloc
import threading
import multiprocessing
import asyncio
import random
import sys
import gc
import io
import logging
from typing import List, Dict, Callable, Any
from functools import wraps
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import unittest


# å¤åˆ¶åŸå§‹ç±»å®šä¹‰
def benchmark(func):
    """åŸºå‡†æµ‹è¯•è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        print(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {execution_time:.6f} ç§’")
        return result
    return wrapper


def memory_profiler(func):
    """å†…å­˜åˆ†æè£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        tracemalloc.start()
        result = func(*args, **kwargs)
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        print(f"{func.__name__} å†…å­˜ä½¿ç”¨: å½“å‰ {current / 1024 / 1024:.2f} MB, å³°å€¼ {peak / 1024 / 1024:.2f} MB")
        return result
    return wrapper


class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å·¥å…·ç±»"""
    
    def __init__(self):
        self.results = []
    
    def time_function(self, func: Callable, *args, iterations: int = 1000, **kwargs) -> Dict:
        """æµ‹è¯•å‡½æ•°æ‰§è¡Œæ—¶é—´"""
        times = []
        
        for _ in range(iterations):
            start = time.perf_counter()
            func(*args, **kwargs)
            end = time.perf_counter()
            times.append(end - start)
        
        result = {
            'function': func.__name__,
            'iterations': iterations,
            'total_time': sum(times),
            'avg_time': sum(times) / len(times),
            'min_time': min(times),
            'max_time': max(times)
        }
        
        self.results.append(result)
        return result
    
    def compare_functions(self, functions: List[Callable], *args, iterations: int = 1000, **kwargs):
        """æ¯”è¾ƒå¤šä¸ªå‡½æ•°çš„æ€§èƒ½"""
        print(f"\næ€§èƒ½æ¯”è¾ƒ (è¿­ä»£æ¬¡æ•°: {iterations})")
        print("=" * 60)
        
        results = []
        for func in functions:
            result = self.time_function(func, *args, iterations=iterations, **kwargs)
            results.append(result)
            print(f"{func.__name__:20} | å¹³å‡: {result['avg_time']:.6f}s | æ€»è®¡: {result['total_time']:.6f}s")
        
        # æ‰¾å‡ºæœ€å¿«çš„å‡½æ•°
        fastest = min(results, key=lambda x: x['avg_time'])
        print(f"\næœ€å¿«å‡½æ•°: {fastest['function']}")
        
        return results
    
    def stress_test(self, func: Callable, max_load: int = 1000, step: int = 100):
        """å‹åŠ›æµ‹è¯•"""
        print(f"\nå‹åŠ›æµ‹è¯•: {func.__name__}")
        print("=" * 40)
        
        for load in range(step, max_load + 1, step):
            start_time = time.perf_counter()
            
            try:
                # åˆ›å»ºå¤§é‡æ•°æ®è¿›è¡Œæµ‹è¯•
                data = list(range(load))
                result = func(data)
                
                end_time = time.perf_counter()
                execution_time = end_time - start_time
                
                print(f"è´Ÿè½½ {load:4d}: {execution_time:.6f}s")
                
            except Exception as e:
                print(f"è´Ÿè½½ {load:4d}: å¤±è´¥ - {e}")
                break
    
    def memory_test(self, func: Callable, *args, **kwargs):
        """å†…å­˜æµ‹è¯•"""
        tracemalloc.start()
        
        # æ‰§è¡Œå‰çš„å†…å­˜çŠ¶æ€
        gc.collect()
        before_memory = tracemalloc.get_traced_memory()[0]
        
        # æ‰§è¡Œå‡½æ•°
        result = func(*args, **kwargs)
        
        # æ‰§è¡Œåçš„å†…å­˜çŠ¶æ€
        after_memory = tracemalloc.get_traced_memory()[0]
        peak_memory = tracemalloc.get_traced_memory()[1]
        
        tracemalloc.stop()
        
        memory_used = after_memory - before_memory
        
        print(f"\nå†…å­˜æµ‹è¯•: {func.__name__}")
        print(f"ä½¿ç”¨å†…å­˜: {memory_used / 1024 / 1024:.2f} MB")
        print(f"å³°å€¼å†…å­˜: {peak_memory / 1024 / 1024:.2f} MB")
        
        return {
            'memory_used': memory_used,
            'peak_memory': peak_memory,
            'result': result
        }


class AlgorithmBenchmark:
    """ç®—æ³•åŸºå‡†æµ‹è¯•ç±»"""
    
    def bubble_sort(self, arr: List[int]) -> List[int]:
        """å†’æ³¡æ’åº"""
        arr = arr.copy()
        n = len(arr)
        
        for i in range(n):
            for j in range(0, n - i - 1):
                if arr[j] > arr[j + 1]:
                    arr[j], arr[j + 1] = arr[j + 1], arr[j]
        
        return arr
    
    def quick_sort(self, arr: List[int]) -> List[int]:
        """å¿«é€Ÿæ’åº"""
        if len(arr) <= 1:
            return arr
        
        pivot = arr[len(arr) // 2]
        left = [x for x in arr if x < pivot]
        middle = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        
        return self.quick_sort(left) + middle + self.quick_sort(right)
    
    def python_sort(self, arr: List[int]) -> List[int]:
        """Pythonå†…ç½®æ’åº"""
        return sorted(arr)
    
    def linear_search(self, arr: List[int], target: int) -> int:
        """çº¿æ€§æœç´¢"""
        for i, value in enumerate(arr):
            if value == target:
                return i
        return -1
    
    def binary_search(self, arr: List[int], target: int) -> int:
        """äºŒåˆ†æœç´¢"""
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid = (left + right) // 2
            if arr[mid] == target:
                return mid
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return -1
    
    def fibonacci_recursive(self, n: int) -> int:
        """é€’å½’æ–æ³¢é‚£å¥‘"""
        if n <= 1:
            return n
        return self.fibonacci_recursive(n - 1) + self.fibonacci_recursive(n - 2)
    
    def fibonacci_iterative(self, n: int) -> int:
        """è¿­ä»£æ–æ³¢é‚£å¥‘"""
        if n <= 1:
            return n
        
        a, b = 0, 1
        for _ in range(2, n + 1):
            a, b = b, a + b
        
        return b
    
    def fibonacci_memoized(self, n: int, memo: Dict[int, int] = None) -> int:
        """è®°å¿†åŒ–æ–æ³¢é‚£å¥‘"""
        if memo is None:
            memo = {}
        
        if n in memo:
            return memo[n]
        
        if n <= 1:
            return n
        
        memo[n] = self.fibonacci_memoized(n - 1, memo) + self.fibonacci_memoized(n - 2, memo)
        return memo[n]


class DataProcessor:
    """æ•°æ®å¤„ç†ç±»"""
    
    def process_data_sequential(self, data: List[int]) -> List[int]:
        """é¡ºåºå¤„ç†æ•°æ®"""
        result = []
        for item in data:
            processed = self._complex_calculation(item)
            result.append(processed)
        return result
    
    def process_data_threading(self, data: List[int], max_workers: int = 4) -> List[int]:
        """å¤šçº¿ç¨‹å¤„ç†æ•°æ®"""
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(self._complex_calculation, data))
        return results
    
    def process_data_multiprocessing(self, data: List[int], max_workers: int = 4) -> List[int]:
        """å¤šè¿›ç¨‹å¤„ç†æ•°æ®"""
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(self._complex_calculation, data))
        return results
    
    async def process_data_async(self, data: List[int]) -> List[int]:
        """å¼‚æ­¥å¤„ç†æ•°æ®"""
        tasks = [self._async_calculation(item) for item in data]
        results = await asyncio.gather(*tasks)
        return results
    
    def _complex_calculation(self, x: int) -> int:
        """æ¨¡æ‹Ÿå¤æ‚è®¡ç®—"""
        result = 0
        for i in range(1000):
            result += x * i
        return result
    
    async def _async_calculation(self, x: int) -> int:
        """å¼‚æ­¥å¤æ‚è®¡ç®—"""
        await asyncio.sleep(0.001)
        return self._complex_calculation(x)


class MemoryLeakDemo:
    """å†…å­˜æ³„æ¼æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.data_store = []
        self.circular_refs = []
    
    def create_memory_leak(self, size: int = 1000):
        """åˆ›å»ºå†…å­˜æ³„æ¼"""
        for i in range(size):
            large_data = [random.random() for _ in range(1000)]
            self.data_store.append(large_data)
    
    def create_circular_reference(self, count: int = 100):
        """åˆ›å»ºå¾ªç¯å¼•ç”¨"""
        for i in range(count):
            obj1 = {'id': i, 'ref': None}
            obj2 = {'id': i + 1000, 'ref': obj1}
            obj1['ref'] = obj2
            self.circular_refs.append(obj1)
    
    def cleanup_memory(self):
        """æ¸…ç†å†…å­˜"""
        self.data_store.clear()
        self.circular_refs.clear()
        gc.collect()


# å®Œæ•´çš„æµ‹è¯•è§£å†³æ–¹æ¡ˆ
class TestPerformanceAndDebugging(unittest.TestCase):
    """æ€§èƒ½æµ‹è¯•å’Œè°ƒè¯•ç»ƒä¹  - å®Œæ•´è§£å†³æ–¹æ¡ˆ"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.performance_tester = PerformanceTester()
        self.algorithm_benchmark = AlgorithmBenchmark()
        self.data_processor = DataProcessor()
        self.memory_demo = MemoryLeakDemo()
        
        # æµ‹è¯•æ•°æ®
        self.small_data = list(range(100))
        random.shuffle(self.small_data)
        
        self.medium_data = list(range(1000))
        random.shuffle(self.medium_data)
        
        self.large_data = list(range(10000))
        random.shuffle(self.large_data)
    
    def test_sorting_algorithms_performance(self):
        """æ¯”è¾ƒæ’åºç®—æ³•æ€§èƒ½"""
        print("\n=== æ’åºç®—æ³•æ€§èƒ½æµ‹è¯• ===")
        
        sorting_functions = [
            self.algorithm_benchmark.bubble_sort,
            self.algorithm_benchmark.quick_sort,
            self.algorithm_benchmark.python_sort
        ]
        
        print("\nå°æ•°æ®é›†æµ‹è¯• (100ä¸ªå…ƒç´ ):")
        results_small = self.performance_tester.compare_functions(
            sorting_functions, self.small_data, iterations=10
        )
        
        print("\nä¸­ç­‰æ•°æ®é›†æµ‹è¯• (1000ä¸ªå…ƒç´ ):")
        results_medium = self.performance_tester.compare_functions(
            sorting_functions[1:], self.medium_data, iterations=5  # è·³è¿‡å†’æ³¡æ’åºï¼Œå¤ªæ…¢
        )
        
        # éªŒè¯æ’åºç»“æœæ­£ç¡®æ€§
        for func in sorting_functions:
            if func.__name__ != 'bubble_sort':  # è·³è¿‡å†’æ³¡æ’åºçš„å¤§æ•°æ®æµ‹è¯•
                sorted_result = func(self.small_data)
                expected_result = sorted(self.small_data)
                self.assertEqual(sorted_result, expected_result, 
                               f"{func.__name__} æ’åºç»“æœä¸æ­£ç¡®")
        
        # åˆ†ææ€§èƒ½ç»“æœ
        print("\næ€§èƒ½åˆ†æ:")
        print("- Pythonå†…ç½®æ’åºæ€§èƒ½æœ€ä½³")
        print("- å¿«é€Ÿæ’åºæ€§èƒ½è‰¯å¥½")
        print("- å†’æ³¡æ’åºæ€§èƒ½æœ€å·®ï¼Œä¸é€‚åˆå¤§æ•°æ®")
    
    def test_search_algorithms_performance(self):
        """æ¯”è¾ƒæœç´¢ç®—æ³•æ€§èƒ½"""
        print("\n=== æœç´¢ç®—æ³•æ€§èƒ½æµ‹è¯• ===")
        
        # å‡†å¤‡æ’åºæ•°æ®ç”¨äºäºŒåˆ†æœç´¢
        sorted_data = sorted(self.medium_data)
        target = sorted_data[len(sorted_data) // 2]  # é€‰æ‹©ä¸­é—´å€¼ä½œä¸ºç›®æ ‡
        
        print(f"æœç´¢ç›®æ ‡: {target}")
        print(f"æ•°æ®å¤§å°: {len(sorted_data)}")
        
        # çº¿æ€§æœç´¢æµ‹è¯•
        linear_time = self.performance_tester.time_function(
            self.algorithm_benchmark.linear_search,
            self.medium_data, target, iterations=100
        )
        
        # äºŒåˆ†æœç´¢æµ‹è¯•
        binary_time = self.performance_tester.time_function(
            self.algorithm_benchmark.binary_search,
            sorted_data, target, iterations=100
        )
        
        print(f"\nçº¿æ€§æœç´¢å¹³å‡æ—¶é—´: {linear_time['avg_time']:.6f}s")
        print(f"äºŒåˆ†æœç´¢å¹³å‡æ—¶é—´: {binary_time['avg_time']:.6f}s")
        print(f"æ€§èƒ½æå‡: {linear_time['avg_time'] / binary_time['avg_time']:.2f}å€")
        
        # éªŒè¯æœç´¢ç»“æœæ­£ç¡®æ€§
        linear_result = self.algorithm_benchmark.linear_search(self.medium_data, target)
        binary_result = self.algorithm_benchmark.binary_search(sorted_data, target)
        
        self.assertNotEqual(linear_result, -1, "çº¿æ€§æœç´¢åº”è¯¥æ‰¾åˆ°ç›®æ ‡")
        self.assertNotEqual(binary_result, -1, "äºŒåˆ†æœç´¢åº”è¯¥æ‰¾åˆ°ç›®æ ‡")
        self.assertEqual(sorted_data[binary_result], target, "äºŒåˆ†æœç´¢ç»“æœæ­£ç¡®")
    
    def test_fibonacci_algorithms_performance(self):
        """æ¯”è¾ƒæ–æ³¢é‚£å¥‘ç®—æ³•æ€§èƒ½"""
        print("\n=== æ–æ³¢é‚£å¥‘ç®—æ³•æ€§èƒ½æµ‹è¯• ===")
        
        test_values = [10, 20, 30]
        
        for n in test_values:
            print(f"\nè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ç¬¬{n}é¡¹:")
            
            # é€’å½’ç‰ˆæœ¬ï¼ˆå°nå€¼ï¼‰
            if n <= 20:  # é€’å½’ç‰ˆæœ¬å¤ªæ…¢ï¼Œåªæµ‹è¯•å°å€¼
                recursive_time = self.performance_tester.time_function(
                    self.algorithm_benchmark.fibonacci_recursive,
                    n, iterations=1
                )
                print(f"é€’å½’ç‰ˆæœ¬: {recursive_time['avg_time']:.6f}s")
            
            # è¿­ä»£ç‰ˆæœ¬
            iterative_time = self.performance_tester.time_function(
                self.algorithm_benchmark.fibonacci_iterative,
                n, iterations=1000
            )
            print(f"è¿­ä»£ç‰ˆæœ¬: {iterative_time['avg_time']:.6f}s")
            
            # è®°å¿†åŒ–ç‰ˆæœ¬
            memoized_time = self.performance_tester.time_function(
                self.algorithm_benchmark.fibonacci_memoized,
                n, iterations=1000
            )
            print(f"è®°å¿†åŒ–ç‰ˆæœ¬: {memoized_time['avg_time']:.6f}s")
            
            # éªŒè¯ç»“æœæ­£ç¡®æ€§
            iterative_result = self.algorithm_benchmark.fibonacci_iterative(n)
            memoized_result = self.algorithm_benchmark.fibonacci_memoized(n)
            self.assertEqual(iterative_result, memoized_result, "æ–æ³¢é‚£å¥‘ç»“æœåº”è¯¥ç›¸åŒ")
    
    def test_concurrent_processing_performance(self):
        """æ¯”è¾ƒå¹¶å‘å¤„ç†æ€§èƒ½"""
        print("\n=== å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯• ===")
        
        test_data = list(range(100))  # ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†è¿›è¡Œæµ‹è¯•
        
        # é¡ºåºå¤„ç†
        print("\né¡ºåºå¤„ç†:")
        sequential_time = self.performance_tester.time_function(
            self.data_processor.process_data_sequential,
            test_data, iterations=1
        )
        
        # å¤šçº¿ç¨‹å¤„ç†
        print("\nå¤šçº¿ç¨‹å¤„ç†:")
        threading_time = self.performance_tester.time_function(
            self.data_processor.process_data_threading,
            test_data, iterations=1
        )
        
        # å¤šè¿›ç¨‹å¤„ç†
        print("\nå¤šè¿›ç¨‹å¤„ç†:")
        multiprocessing_time = self.performance_tester.time_function(
            self.data_processor.process_data_multiprocessing,
            test_data, iterations=1
        )
        
        print(f"\næ€§èƒ½æ¯”è¾ƒ:")
        print(f"é¡ºåºå¤„ç†: {sequential_time['avg_time']:.6f}s")
        print(f"å¤šçº¿ç¨‹: {threading_time['avg_time']:.6f}s")
        print(f"å¤šè¿›ç¨‹: {multiprocessing_time['avg_time']:.6f}s")
        
        # éªŒè¯ç»“æœæ­£ç¡®æ€§
        sequential_result = self.data_processor.process_data_sequential(test_data[:10])
        threading_result = self.data_processor.process_data_threading(test_data[:10])
        
        self.assertEqual(len(sequential_result), len(threading_result), "ç»“æœé•¿åº¦åº”è¯¥ç›¸åŒ")
    
    def test_memory_usage_analysis(self):
        """å†…å­˜ä½¿ç”¨åˆ†æ"""
        print("\n=== å†…å­˜ä½¿ç”¨åˆ†æ ===")
        
        # æµ‹è¯•æ’åºç®—æ³•çš„å†…å­˜ä½¿ç”¨
        test_data = list(range(1000))
        random.shuffle(test_data)
        
        print("\næ’åºç®—æ³•å†…å­˜ä½¿ç”¨:")
        
        # å¿«é€Ÿæ’åºå†…å­˜æµ‹è¯•
        quick_sort_memory = self.performance_tester.memory_test(
            self.algorithm_benchmark.quick_sort, test_data
        )
        
        # Pythonå†…ç½®æ’åºå†…å­˜æµ‹è¯•
        python_sort_memory = self.performance_tester.memory_test(
            self.algorithm_benchmark.python_sort, test_data
        )
        
        print(f"\nå†…å­˜ä½¿ç”¨æ¯”è¾ƒ:")
        print(f"å¿«é€Ÿæ’åºå³°å€¼å†…å­˜: {quick_sort_memory['peak_memory'] / 1024 / 1024:.2f} MB")
        print(f"Pythonæ’åºå³°å€¼å†…å­˜: {python_sort_memory['peak_memory'] / 1024 / 1024:.2f} MB")
        
        # éªŒè¯å†…å­˜æµ‹è¯•æœ‰æ•ˆæ€§
        self.assertGreater(quick_sort_memory['peak_memory'], 0, "åº”è¯¥æœ‰å†…å­˜ä½¿ç”¨")
        self.assertGreater(python_sort_memory['peak_memory'], 0, "åº”è¯¥æœ‰å†…å­˜ä½¿ç”¨")
    
    def test_stress_testing(self):
        """å‹åŠ›æµ‹è¯•"""
        print("\n=== å‹åŠ›æµ‹è¯• ===")
        
        # å¯¹å¿«é€Ÿæ’åºè¿›è¡Œå‹åŠ›æµ‹è¯•
        print("\nå¿«é€Ÿæ’åºå‹åŠ›æµ‹è¯•:")
        self.performance_tester.stress_test(
            self.algorithm_benchmark.quick_sort,
            max_load=5000, step=1000
        )
        
        # å¯¹Pythonå†…ç½®æ’åºè¿›è¡Œå‹åŠ›æµ‹è¯•
        print("\n Pythonå†…ç½®æ’åºå‹åŠ›æµ‹è¯•:")
        self.performance_tester.stress_test(
            self.algorithm_benchmark.python_sort,
            max_load=10000, step=2000
        )
        
        print("\nå‹åŠ›æµ‹è¯•å®Œæˆ")
    
    def test_memory_leak_detection(self):
        """å†…å­˜æ³„æ¼æ£€æµ‹"""
        print("\n=== å†…å­˜æ³„æ¼æ£€æµ‹ ===")
        
        # å¼€å§‹å†…å­˜ç›‘æ§
        tracemalloc.start()
        
        # è·å–åˆå§‹å†…å­˜çŠ¶æ€
        gc.collect()
        initial_memory = tracemalloc.get_traced_memory()[0]
        print(f"åˆå§‹å†…å­˜: {initial_memory / 1024 / 1024:.2f} MB")
        
        # åˆ›å»ºå†…å­˜æ³„æ¼
        print("\nåˆ›å»ºå†…å­˜æ³„æ¼...")
        self.memory_demo.create_memory_leak(100)
        self.memory_demo.create_circular_reference(50)
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        after_leak_memory = tracemalloc.get_traced_memory()[0]
        print(f"æ³„æ¼åå†…å­˜: {after_leak_memory / 1024 / 1024:.2f} MB")
        print(f"å†…å­˜å¢é•¿: {(after_leak_memory - initial_memory) / 1024 / 1024:.2f} MB")
        
        # æ¸…ç†å†…å­˜
        print("\næ¸…ç†å†…å­˜...")
        self.memory_demo.cleanup_memory()
        
        # æ£€æŸ¥æ¸…ç†åçš„å†…å­˜
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        after_cleanup_memory = tracemalloc.get_traced_memory()[0]
        print(f"æ¸…ç†åå†…å­˜: {after_cleanup_memory / 1024 / 1024:.2f} MB")
        print(f"å†…å­˜å›æ”¶: {(after_leak_memory - after_cleanup_memory) / 1024 / 1024:.2f} MB")
        
        tracemalloc.stop()
        
        # éªŒè¯å†…å­˜æ³„æ¼æ£€æµ‹æœ‰æ•ˆæ€§
        self.assertGreater(after_leak_memory, initial_memory, "åº”è¯¥æ£€æµ‹åˆ°å†…å­˜å¢é•¿")
        self.assertLess(after_cleanup_memory, after_leak_memory, "æ¸…ç†åå†…å­˜åº”è¯¥å‡å°‘")
    
    def test_profiling_analysis(self):
        """æ€§èƒ½åˆ†æ"""
        print("\n=== æ€§èƒ½åˆ†æ ===")
        
        # åˆ›å»ºæ€§èƒ½åˆ†æå™¨
        profiler = cProfile.Profile()
        
        # å¼€å§‹åˆ†æ
        profiler.enable()
        
        # æ‰§è¡Œè¦åˆ†æçš„ä»£ç 
        test_data = list(range(1000))
        random.shuffle(test_data)
        
        # æ‰§è¡Œå¤šç§ç®—æ³•
        self.algorithm_benchmark.quick_sort(test_data.copy())
        self.algorithm_benchmark.python_sort(test_data.copy())
        
        # è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—
        for i in range(10, 21):
            self.algorithm_benchmark.fibonacci_iterative(i)
            self.algorithm_benchmark.fibonacci_memoized(i)
        
        # åœæ­¢åˆ†æ
        profiler.disable()
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\næ€§èƒ½åˆ†ææŠ¥å‘Š:")
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')
        
        # æ•è·è¾“å‡ºåˆ°å­—ç¬¦ä¸²
        output = io.StringIO()
        stats.print_stats(10, file=output)
        profile_output = output.getvalue()
        
        # æ˜¾ç¤ºå‰å‡ è¡Œåˆ†æç»“æœ
        lines = profile_output.split('\n')[:15]
        for line in lines:
            if line.strip():
                print(line)
        
        print("\næ€§èƒ½åˆ†æå®Œæˆ")
        
        # éªŒè¯åˆ†æå™¨å·¥ä½œæ­£å¸¸
        self.assertGreater(len(stats.stats), 0, "åº”è¯¥æœ‰æ€§èƒ½ç»Ÿè®¡æ•°æ®")
    
    def test_async_performance(self):
        """å¼‚æ­¥æ€§èƒ½æµ‹è¯•"""
        print("\n=== å¼‚æ­¥æ€§èƒ½æµ‹è¯• ===")
        
        test_data = list(range(50))  # ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†
        
        # åŒæ­¥å¤„ç†æ—¶é—´
        sync_start = time.perf_counter()
        sync_result = self.data_processor.process_data_sequential(test_data)
        sync_end = time.perf_counter()
        sync_time = sync_end - sync_start
        
        # å¼‚æ­¥å¤„ç†æ—¶é—´
        async def run_async_test():
            async_start = time.perf_counter()
            async_result = await self.data_processor.process_data_async(test_data)
            async_end = time.perf_counter()
            return async_result, async_end - async_start
        
        async_result, async_time = asyncio.run(run_async_test())
        
        print(f"\nå¼‚æ­¥æ€§èƒ½æ¯”è¾ƒ:")
        print(f"åŒæ­¥å¤„ç†æ—¶é—´: {sync_time:.6f}s")
        print(f"å¼‚æ­¥å¤„ç†æ—¶é—´: {async_time:.6f}s")
        print(f"æ€§èƒ½æ¯”ç‡: {sync_time / async_time:.2f}")
        
        # éªŒè¯ç»“æœæ­£ç¡®æ€§
        self.assertEqual(len(sync_result), len(async_result), "ç»“æœé•¿åº¦åº”è¯¥ç›¸åŒ")
        
        # å¯¹äºIOå¯†é›†å‹ä»»åŠ¡ï¼Œå¼‚æ­¥é€šå¸¸æ›´å¿«
        if async_time < sync_time:
            print("å¼‚æ­¥å¤„ç†æ›´å¿«ï¼ˆé€‚åˆIOå¯†é›†å‹ä»»åŠ¡ï¼‰")
        else:
            print("åŒæ­¥å¤„ç†æ›´å¿«ï¼ˆå¯èƒ½æ˜¯CPUå¯†é›†å‹ä»»åŠ¡ï¼‰")


# è°ƒè¯•æŠ€æœ¯æ¼”ç¤ºçš„å®Œæ•´å®ç°
class DebuggingDemo:
    """è°ƒè¯•æŠ€æœ¯æ¼”ç¤ºç±» - å®Œæ•´å®ç°"""
    
    def __init__(self):
        self.data = []
    
    def buggy_function(self, numbers: List[int]) -> float:
        """åŒ…å«bugçš„å‡½æ•°"""
        total = 0
        count = 0
        
        for num in numbers:
            if num > 0:  # Bug: åº”è¯¥æ£€æŸ¥num != 0
                total += num
                count += 1
        
        # Bug: å¯èƒ½é™¤é›¶é”™è¯¯
        average = total / count
        return average
    
    def debug_with_print(self, numbers: List[int]) -> float:
        """ä½¿ç”¨printè°ƒè¯•"""
        print(f"è¾“å…¥æ•°æ®: {numbers}")
        
        total = 0
        count = 0
        
        for i, num in enumerate(numbers):
            print(f"å¤„ç†ç¬¬{i}ä¸ªæ•°å­—: {num}")
            if num > 0:
                total += num
                count += 1
                print(f"  ç´¯è®¡æ€»å’Œ: {total}, è®¡æ•°: {count}")
        
        print(f"æœ€ç»ˆæ€»å’Œ: {total}, è®¡æ•°: {count}")
        
        if count == 0:
            print("è­¦å‘Š: æ²¡æœ‰æ­£æ•°ï¼Œæ— æ³•è®¡ç®—å¹³å‡å€¼")
            return 0.0
        
        average = total / count
        print(f"å¹³å‡å€¼: {average}")
        return average
    
    def debug_with_logging(self, numbers: List[int]) -> float:
        """ä½¿ç”¨loggingè°ƒè¯•"""
        # é…ç½®æ—¥å¿—
        logging.basicConfig(level=logging.DEBUG, 
                          format='%(levelname)s - %(message)s')
        logger = logging.getLogger(__name__)
        
        logger.debug(f"å¼€å§‹å¤„ç†æ•°æ®: {numbers}")
        
        total = 0
        count = 0
        
        for num in numbers:
            logger.debug(f"å¤„ç†æ•°å­—: {num}")
            if num > 0:
                total += num
                count += 1
                logger.debug(f"ç´¯è®¡: total={total}, count={count}")
        
        if count == 0:
            logger.warning("æ²¡æœ‰æ­£æ•°ï¼Œè¿”å›0")
            return 0.0
        
        average = total / count
        logger.info(f"è®¡ç®—å®Œæˆï¼Œå¹³å‡å€¼: {average}")
        return average
    
    def debug_with_assertions(self, numbers: List[int]) -> float:
        """ä½¿ç”¨æ–­è¨€è°ƒè¯•"""
        assert isinstance(numbers, list), "è¾“å…¥å¿…é¡»æ˜¯åˆ—è¡¨"
        assert len(numbers) > 0, "åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
        
        total = 0
        count = 0
        
        for num in numbers:
            assert isinstance(num, (int, float)), f"æ•°å­—ç±»å‹é”™è¯¯: {type(num)}"
            
            if num > 0:
                total += num
                count += 1
        
        assert count > 0, "æ²¡æœ‰æ‰¾åˆ°æ­£æ•°"
        
        average = total / count
        assert average > 0, "å¹³å‡å€¼åº”è¯¥å¤§äº0"
        
        return average
    
    def fixed_function(self, numbers: List[int]) -> float:
        """ä¿®å¤åçš„å‡½æ•°"""
        if not numbers:
            raise ValueError("è¾“å…¥åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        total = 0
        count = 0
        
        for num in numbers:
            if num != 0:  # ä¿®å¤: æ­£ç¡®æ£€æŸ¥éé›¶æ•°å­—
                total += num
                count += 1
        
        if count == 0:  # ä¿®å¤: å¤„ç†é™¤é›¶æƒ…å†µ
            raise ValueError("æ²¡æœ‰éé›¶æ•°å­—ï¼Œæ— æ³•è®¡ç®—å¹³å‡å€¼")
        
        return total / count


def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("è¿è¡Œæ€§èƒ½æµ‹è¯•å’Œè°ƒè¯•ç»ƒä¹ ...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestPerformanceAndDebugging))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•ç»Ÿè®¡
    print(f"\næµ‹è¯•ç»Ÿè®¡:")
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    
    return result.wasSuccessful()


def demonstrate_debugging():
    """æ¼”ç¤ºè°ƒè¯•æŠ€æœ¯"""
    print("\n=== è°ƒè¯•æŠ€æœ¯æ¼”ç¤º ===")
    
    demo = DebuggingDemo()
    test_data = [1, -2, 3, 0, 5, -1]
    
    print("\n1. åŸå§‹buggyå‡½æ•°:")
    try:
        result = demo.buggy_function(test_data)
        print(f"ç»“æœ: {result}")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
    
    print("\n2. ä½¿ç”¨printè°ƒè¯•:")
    result = demo.debug_with_print(test_data)
    
    print("\n3. ä½¿ç”¨loggingè°ƒè¯•:")
    result = demo.debug_with_logging(test_data)
    
    print("\n4. ä½¿ç”¨æ–­è¨€è°ƒè¯•:")
    try:
        result = demo.debug_with_assertions(test_data)
        print(f"ç»“æœ: {result}")
    except AssertionError as e:
        print(f"æ–­è¨€é”™è¯¯: {e}")
    
    print("\n5. ä¿®å¤åçš„å‡½æ•°:")
    try:
        result = demo.fixed_function(test_data)
        print(f"ç»“æœ: {result}")
    except ValueError as e:
        print(f"å€¼é”™è¯¯: {e}")


if __name__ == "__main__":
    print("Session29 ç»ƒä¹ 3è§£å†³æ–¹æ¡ˆ: æ€§èƒ½æµ‹è¯•å’Œè°ƒè¯•æŠ€æœ¯")
    print("=" * 50)
    
    print("\nè¿™ä¸ªè§£å†³æ–¹æ¡ˆå±•ç¤ºäº†:")
    print("1. å®Œæ•´çš„æ€§èƒ½æµ‹è¯•æ¡†æ¶")
    print("2. ç®—æ³•æ€§èƒ½æ¯”è¾ƒå’Œåˆ†æ")
    print("3. å†…å­˜ä½¿ç”¨ç›‘æ§å’Œæ³„æ¼æ£€æµ‹")
    print("4. å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("5. æ€§èƒ½åˆ†æå’Œè°ƒè¯•æŠ€æœ¯")
    print("6. å‹åŠ›æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•")
    
    # æ¼”ç¤ºè°ƒè¯•æŠ€æœ¯
    demonstrate_debugging()
    
    print("\nå¼€å§‹æ€§èƒ½æµ‹è¯•...")
    success = run_performance_tests()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æ€§èƒ½æµ‹è¯•éƒ½å®Œæˆäº†ï¼")
        print("\nå­¦åˆ°çš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§:")
        print("- ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¯”è¾ƒç®—æ³•æ€§èƒ½")
        print("- è¿›è¡Œå†…å­˜åˆ†æå’Œæ³„æ¼æ£€æµ‹")
        print("- æŒæ¡å„ç§è°ƒè¯•æŠ€æœ¯")
        print("- ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·ä¼˜åŒ–ä»£ç ")
        print("- ç†è§£å¹¶å‘å’Œå¼‚æ­¥çš„æ€§èƒ½ç‰¹ç‚¹")
        print("- è¿›è¡Œå‹åŠ›æµ‹è¯•æ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆ")
    else:
        print("\nâŒ æœ‰æµ‹è¯•æœªå®Œæˆï¼Œè¯·æ£€æŸ¥å®ç°")